Color constancy is the ability to recognize colors of objects independent of the color of the light source.Approaches to this problem can be divided into two groups. For the ﬁrst group, the aim is to represent images by features which are invariant with respect to the light source, for example within the context of image retrieval. Such invariant representation have been proposed by Funt and Finlayson [5], Gevers and Smeulders [2], Geusebroek et al. [6], and Van de Weijer and Schmid [7]. For these methods the actual estimation of the light source is not necessary. For the second group of approaches, the aim is to correct images for deviations from a canonical light source. Contrary to methods in the ﬁrst group, solutions to this problem do estimate the color of the light source, be it explicitly or implicitly. Methods, either propose a light source estimation, after which the image is corrected [8], [9], [10] [11], or they directly estimate the color corrected image [1], [12], after which the light source can be derived. If desired, illuminant invariant features can subsequently be derived from the corrected image. In this paper we look at color constancy approaches of the second group, i.e. methods from which a light source corrected image can be computed. 

Grey World Hypothesis
The image values, f = (R,G,B)T, for a Lambertian surface are dependent on the light source e(λ), where λ is the wavelength, the surface reﬂectance s(λ) and the camera sensitivity functions c(λ) = (R(λ),G(λ),B(λ))

where ω is the visible spectrum and bold fonts are applied for vectors. We assume that the scene is illuminated by a single light source. The goal of color constancy is to estimate the light source color e(λ), or its projection on the RGB-kernels, 

given the image values f (x), where x is the spatial coordinate in the image. The task of color constancy is not attainable without further assumptions.

Grey Edge Hypothesis

As an alternative to the Grey-World hypothesis, we propose the Grey-Edge hypothesis: the average of the reﬂectance differences in a scene is achromatic

The subscript x indicates the spatial derivative at scale σ. With the Grey-Edge assumption, the light source color can be computed from the average color derivative in the image given by: 

The Grey-Edge hypothesis originates from the observation that the color derivative distribution of images forms a relatively regular, ellipsoidlike shape, of which the long axis coincides with the light source color

color derivative distribution is depicted for three images. The color derivatives are rotated to the opponent color space as follows: 

In the opponent color space, O3 coincides with the white light direction. For the scene under white light (the leftmost picture), the distribution of the derivatives are centered along the O3 i.e. the white-light axis. Once we change the color of the light source, as in the second and third picture, the distribution of the color derivatives no longer align with the white-light axis. In other words, color constancy based on the Grey-Edge assumption can be interpreted as skewing the color derivative distribution such that the average derivative is in the O3 orientation

ﬂectance in a scene is achromatic. We distinguish two special cases. For p = 1, the illuminant is derived by a normal averaging operation over the derivatives of the channels. For p =∞, the illuminant is computed from the maximum derivative in the scene. The resemblance between the color constancy derivation from the Grey-World and Grey-Edge hypothesis is apparent. Both methods can be combined in a single framework of color constancy methods based on low-level image features derived from the following general hypothesis: 

ivision byRdx has been incorporated into the constant k. Next to the already discussed hypotheses (Grey-World, max-RGB, Minkowski norm, and the newly proposed Grey-Edge), it is obvious that this framework also includes higher order based color constancy. High-order derivatives have correspondences with the center-surround mechanism of the human eyes for color constancy such as exploited in the well-known center-surround retinex algorithm [21]. The inﬂuence of the color intensities could be weighted according to their distance to the center of the receptive ﬁeld generally calculated by a difference of Gaussian functions.

The illuminant estimation of Eq. 17 describes a framework for low-level based illuminant estimation. This framework produces different estimations for the illuminant color based on three variables: 1) The order, n, of the image structure is the parameter determining if the method is a GreyWorld or a Grey-Edge algorithm. The Grey-World methods are based on the RGB values, whereas the Grey-Edge methods are based on the spatial derivatives of order n. In this paper, we will investigate higher-order based color constancy up to order n = 2. 2) TheMinkowskinorm p whichdeterminestherelativeweightsofthemultiplemeasurements from which the ﬁnal illuminant color is estimated. A high Minkowski norm emphasizes larger measurements whereas a low Minkowski norm equally distributes weights among the measurements. 3) The scale of the local measurements as denoted by σ. For ﬁrst or higher order estimation, this local scale is combined with the differentiation operation computed with the Gaussian derivative. For zero-order Grey-World methods, this local scale is imposed by a Gaussian smoothing operation. An overview of the instantiations of the illuminant estimation given by the framework of Eq. 17, which are considered in this paper, is given in Table I. An advantage of the color constancy methods based on Eq. 17 is that they are all based on low computational demanding operations. In fact, the p-th Minkowski norm of (smoothed) RGB values or derivatives can be computed extremely fast (even real-time on dedicated hardware). Furthermore, the method does not require an image database taken under a known light source for calibration as is necessary for more complex color constancy methods such as color gamut mapping, and color by correlation [1], [15].

